name: Market Snapshot (6m) -> BigQuery (latest)

on:
  workflow_dispatch:
  schedule:
    - cron: "*/6 * * * *"

# Evita solapes: si tarda >6m, cancela el anterior
concurrency:
  group: market-snapshot-and-bq
  cancel-in-progress: true

permissions:
  contents: read
  id-token: write

jobs:
  snapshot_and_load:
    runs-on: ubuntu-latest
    timeout-minutes: 6

    env:
      PROJECT_ID: eve-market-sandbox
      PROJECT_NUMBER: "791118475780"
      LOCATION: EU
      DATASET_ID: eve_market
      TABLE_LATEST: market_orders_latest
      OUT_DIR: out
      REQUIRED_REGION: "10000002"

      # ⚠️ AJUSTA SI TU PROVIDER NO SE LLAMA "github"
      WIF_PROVIDER: projects/791118475780/locations/global/workloadIdentityPools/eve-market-gh-pool/providers/github
      SERVICE_ACCOUNT: eve-market-bq-loader@eve-market-sandbox.iam.gserviceaccount.com

      # ESI
      ESI_DATASOURCE: tranquility
      USER_AGENT: "eve-esi-market-cloud-reader (github: loscamperoslozanopardo-dotcom/eve-esi-market-cloud-reader)"
      WORKERS: "20"
      STATE_FILE: "out/state/market_headers.json"
      BOOTSTRAP: "1"
      FORCE_VERIFY_AFTER_EXPIRES: "1"
      ERROR_LIMIT_THRESHOLD: "20"
      MAX_RETRIES: "5"
      TIMEOUT_S: "60"

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 1) Genera snapshot (market_orders_all.jsonl.gz + manifest.json + state headers)
      - name: Run market snapshot (full)
        run: |
          mkdir -p "${OUT_DIR}"
          python src/market_full_20w.py

      # 2) Gate: SOLO cargamos a BQ si cumple:
      # regions_to_fetch > 20, orders_ok > 0, y 10000002 NO está en failed_regions
      - name: Gate (check manifest requirements)
        id: gate
        shell: bash
        run: |
          python - <<'PY'
          import json, os, sys

          out_dir = os.environ.get("OUT_DIR", "out")
          manifest_path = os.path.join(out_dir, "manifest.json")

          load_ok = False
          if not os.path.exists(manifest_path):
              print(f"::error::Missing manifest.json at {manifest_path}")
          else:
              with open(manifest_path, "r", encoding="utf-8") as f:
                  m = json.load(f)

              regions_to_fetch = int(m.get("regions_to_fetch", 0))
              orders_ok = int(m.get("orders_ok", 0))

              failed_ids = []
              fr = m.get("failed_regions", [])
              if isinstance(fr, list):
                  for item in fr:
                      if isinstance(item, dict) and "region_id" in item:
                          failed_ids.append(str(item["region_id"]))

              required_region = str(os.environ.get("REQUIRED_REGION", "10000002"))
              load_ok = (regions_to_fetch > 20 and orders_ok > 0 and required_region not in failed_ids)

              print(f"regions_to_fetch={regions_to_fetch}")
              print(f"orders_ok={orders_ok}")
              print(f"failed_ids_count={len(failed_ids)}")
              print(f"required_region_failed={required_region in failed_ids}")
              print(f"LOAD_OK={load_ok}")

          outp = os.environ.get("GITHUB_OUTPUT")
          if not outp:
              print("::error::GITHUB_OUTPUT not set")
              sys.exit(1)

          with open(outp, "a", encoding="utf-8") as f:
              f.write(f"load_ok={'true' if load_ok else 'false'}\n")
          PY

      # 3) Auth (WIF) SOLO si gate ok
      - name: Auth to Google Cloud (WIF)
        if: steps.gate.outputs.load_ok == 'true'
        uses: google-github-actions/auth@v3
        with:
          project_id: ${{ env.PROJECT_ID }}
          workload_identity_provider: ${{ env.WIF_PROVIDER }}
          service_account: ${{ env.SERVICE_ACCOUNT }}
          create_credentials_file: true
          export_environment_variables: true
          token_format: access_token
          access_token_scopes: https://www.googleapis.com/auth/cloud-platform

      - name: Setup gcloud
        if: steps.gate.outputs.load_ok == 'true'
        uses: google-github-actions/setup-gcloud@v2

      # 4) Crear tabla si no existe (schema fijo) y cargar REEMPLAZANDO (sin restos)
      - name: Create table (if not exists) + Load overwrite
        if: steps.gate.outputs.load_ok == 'true'
        shell: bash
        run: |
          set -euo pipefail

          # Crea dataset (por si acaso) y tabla si no existe
          bq --location="${LOCATION}" mk --dataset --if_not_exists "${PROJECT_ID}:${DATASET_ID}"

          # Schema ESI market orders (order_type=all)
          # Nota: si algún campo extra aparece, ignore_unknown_values evita que falle.
          bq --location="${LOCATION}" query --use_legacy_sql=false "
          CREATE TABLE IF NOT EXISTS \`${PROJECT_ID}.${DATASET_ID}.${TABLE_LATEST}\` (
            duration INT64,
            is_buy_order BOOL,
            issued TIMESTAMP,
            location_id INT64,
            min_volume INT64,
            order_id INT64,
            price FLOAT64,
            range STRING,
            system_id INT64,
            type_id INT64,
            volume_remain INT64,
            volume_total INT64
          );"

          # Load: NEWLINE_DELIMITED_JSON comprimido (gzip) -> REPLACE (sobrescribe sin restos)
          bq --location="${LOCATION}" load --replace \
            --source_format=NEWLINE_DELIMITED_JSON \
            --ignore_unknown_values \
            "${PROJECT_ID}:${DATASET_ID}.${TABLE_LATEST}" \
            "${OUT_DIR}/market_orders_all.jsonl.gz"

      # 5) Subir artifact siempre (para depurar)
      - name: Upload artifact (latest snapshot files)
        uses: actions/upload-artifact@v4
        with:
          name: market-latest
          path: |
            out/market_orders_all.jsonl.gz
            out/manifest.json
            out/state/market_headers.json
          retention-days: 2
